{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcacac0-7181-4114-a092-0751eaa4c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Konfiguration\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Kafka‚ÄêEinstellungen\n",
    "KAFKA_BOOTSTRAP_SERVERS = [\"172.29.16.101:9092\"]\n",
    "KAFKA_TOPIC = \"current-weather-api\"\n",
    "\n",
    "# OpenWeatherMap‚ÄêEinstellungen\n",
    "API_KEY = \"bd5e378503939ddaee76f12ad7a97608\"\n",
    "\n",
    "\n",
    "CITY_IDS = [\n",
    "    2761369,  # Wien\n",
    "    2772400,  # Linz\n",
    "    2778067,  # Graz\n",
    "    2766824,  # Salzburg\n",
    "    2775220,  # Innsbruck\n",
    "    7871497,  # Klagenfurt\n",
    "    2781503,\n",
    "    2782045   # Bregenz\n",
    "    # ... bis zu 20 IDs insgesamt ...\n",
    "]\n",
    "\n",
    "POLL_INTERVAL_SECONDS = 10 \n",
    "\n",
    "MAX_SINGLE_CITY_CALLS_PER_DAY = 960\n",
    "\n",
    "# Darum: Wir limitieren pro Gruppen‚ÄêCall die Anzahl der CITY_IDS auf 10.\n",
    "MAX_IDS_PER_CALL = 10\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) KafkaProducer initialisieren\n",
    "# ------------------------------------------------------------------------------\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    "    value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Tagesz√§hler‚ÄêLogik\n",
    "# ------------------------------------------------------------------------------\n",
    "# Wir tracken, wie viele Einzel‚ÄêStadt‚ÄêAbfragen wir heute bereits gemacht haben.\n",
    "# Bei jedem Gruppen‚ÄêCall wird `current_batch_ids_count` = Anzahl der IDs in diesem Call\n",
    "# zu `daily_city_calls` addiert. Wenn `daily_city_calls` + next_batch_size > MAX_SINGLE_CITY_CALLS_PER_DAY,\n",
    "# brechen wir ab.\n",
    "\n",
    "daily_city_calls = 0\n",
    "\n",
    "# Wir merken uns, an welchem UTC‚ÄêDatum wir gestartet sind. Um Mitternacht UTC zur√ºcksetzen.\n",
    "current_day_utc = datetime.now(timezone.utc).date()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Polling‚ÄêSchleife\n",
    "# ------------------------------------------------------------------------------\n",
    "try:\n",
    "    while True:\n",
    "        now_utc = datetime.now(timezone.utc)\n",
    "\n",
    "        # 4.1) Tageswechsel pr√ºfen (UTC‚ÄêMitternacht): Z√§hler zur√ºcksetzen\n",
    "        if now_utc.date() != current_day_utc:\n",
    "            daily_city_calls = 0\n",
    "            current_day_utc = now_utc.date()\n",
    "            print(f\"[{now_utc.isoformat()}] Neuer Tag (UTC) ‚Äì Tagesz√§hlung zur√ºckgesetzt.\")\n",
    "\n",
    "        # 4.2) Bestimme die n√§chste Teilmenge von CITY_IDS (maximal MAX_IDS_PER_CALL)\n",
    "        ids_to_call = CITY_IDS[:MAX_IDS_PER_CALL]\n",
    "\n",
    "        # Wenn wir mit dem n√§chsten Gruppen‚ÄêCall das Tageslimit √ºberschreiten, abbrechen\n",
    "        if daily_city_calls + len(ids_to_call) > MAX_SINGLE_CITY_CALLS_PER_DAY:\n",
    "            print(\n",
    "                f\"[{now_utc.isoformat()}] Tageslimit von \"\n",
    "                f\"{MAX_SINGLE_CITY_CALLS_PER_DAY} Stadt‚ÄêAbfragen erreicht oder √ºberschritten. \"\n",
    "                \"Beende Producer.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        # 4.3) API‚ÄêCall: Gruppened-Endpoint mit bis zu MAX_IDS_PER_CALL IDs\n",
    "        ids_param = \",\".join(str(i) for i in ids_to_call)\n",
    "        url = (\n",
    "            f\"https://api.openweathermap.org/data/2.5/group\"\n",
    "            f\"?id={ids_param}\"\n",
    "            f\"&units=metric\"\n",
    "            f\"&appid={API_KEY}\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"[{now_utc.isoformat()}] Fehler bei API‚ÄêCall: {e}\")\n",
    "            # Optional: Warte trotzdem Poll‚ÄêIntervall ab und versuche sp√§ter erneut\n",
    "            time.sleep(POLL_INTERVAL_SECONDS)\n",
    "            continue\n",
    "\n",
    "        # 4.4) Parsen und in Kafka‚ÄêTopic pushen\n",
    "        # Die Antwort hat Feld \"list\", das eine Liste von City‚ÄêObjekten enth√§lt\n",
    "        if \"list\" not in data:\n",
    "            print(f\"[{now_utc.isoformat()}] Unerwartete API‚ÄêAntwort (kein 'list'): {data}\")\n",
    "            time.sleep(POLL_INTERVAL_SECONDS)\n",
    "            continue\n",
    "\n",
    "        for city_obj in data[\"list\"]:\n",
    "            # Beispiel‚ÄêStruktur der city_obj:\n",
    "            # {\n",
    "            #   \"id\": 2761369,\n",
    "            #   \"name\": \"Vienna\",\n",
    "            #   \"coord\": {\"lat\":48.2082,\"lon\":16.3738},\n",
    "            #   \"main\": {\"temp\":22.5,\"humidity\":60,\"temp_min\":21.0,\"temp_max\":23.0,...},\n",
    "            #   \"wind\": {\"speed\":3.1,\"deg\":250,...}, ...\n",
    "            #   \"dt\": 1622548800,  # Zeitstempel UTC in Sekunden\n",
    "            #   ...\n",
    "            # }\n",
    "\n",
    "            # Wir bauen unsere eigene JSON‚ÄêNachricht\n",
    "            msg = {\n",
    "                \"city_id\":          city_obj.get(\"id\"),\n",
    "                \"city_name\":        city_obj.get(\"name\"),\n",
    "                \"latitude\":         city_obj.get(\"coord\", {}).get(\"lat\"),\n",
    "                \"longitude\":        city_obj.get(\"coord\", {}).get(\"lon\"),\n",
    "                \"timestamp_utc\":    datetime.utcfromtimestamp(city_obj.get(\"dt\"))\n",
    "                                      .strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"temp_celsius\":     city_obj.get(\"main\", {}).get(\"temp\"),\n",
    "                \"temp_min_c\":       city_obj.get(\"main\", {}).get(\"temp_min\"),\n",
    "                \"temp_max_c\":       city_obj.get(\"main\", {}).get(\"temp_max\"),\n",
    "                \"pressure_hpa\":     city_obj.get(\"main\", {}).get(\"pressure\"),\n",
    "                \"humidity_pct\":     city_obj.get(\"main\", {}).get(\"humidity\"),\n",
    "                \"wind_speed_kph\":   (city_obj.get(\"wind\", {}).get(\"speed\") * 3.6) \n",
    "                                      if city_obj.get(\"wind\", {}).get(\"speed\") is not None \n",
    "                                      else None,\n",
    "                \"wind_direction\":   city_obj.get(\"wind\", {}).get(\"deg\")\n",
    "            }\n",
    "\n",
    "            # Testausgabe in der Konsole\n",
    "            print(json.dumps(msg, indent=2))  # oder einfach: print(msg)\n",
    "            \n",
    "            # Send an Kafka\n",
    "            producer.send(KAFKA_TOPIC, msg)\n",
    "\n",
    "        # 4.5) Flush to ensure publishing\n",
    "        producer.flush()\n",
    "\n",
    "        # 4.6) Tagesz√§hler aktualisieren\n",
    "        daily_city_calls += len(ids_to_call)\n",
    "        print(\n",
    "            f\"[{now_utc.isoformat()}] Gruppen‚ÄêCall mit {len(ids_to_call)} IDs ausgef√ºhrt. \"\n",
    "            f\"Tages‚ÄêSumme Einzel‚ÄêAbfragen: {daily_city_calls}\"\n",
    "        )\n",
    "\n",
    "        # 4.7) Warte f√ºr das n√§chste Polling‚ÄêIntervall\n",
    "        time.sleep(POLL_INTERVAL_SECONDS)\n",
    "\n",
    "finally:\n",
    "    # 4.8) Graceful Shutdown: Kafka‚ÄêProducer schlie√üen\n",
    "    producer.close()\n",
    "    print(\"Producer geschlossen. Skript beendet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccac21-9523-43c8-9b1c-f1170b6eae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üü° Start\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "print(\"üü° Start\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) SparkSession erstellen\n",
    "# ----------------------------------------------------------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaToPostgresStream\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,\"\n",
    "            \"org.postgresql:postgresql:42.7.3\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"DEBUG\")  # oder \"INFO\"\n",
    "\n",
    "print(\"‚úÖ Schritt 1: SparkSession erstellt\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) JSON-Schema\n",
    "# ----------------------------------------------------------------------------\n",
    "schema = StructType([\n",
    "    StructField(\"city_id\",        StringType(), nullable=False),\n",
    "    StructField(\"city_name\",      StringType(), nullable=False),\n",
    "    StructField(\"latitude\",       DoubleType(), nullable=True),\n",
    "    StructField(\"longitude\",      DoubleType(), nullable=True),\n",
    "    StructField(\"timestamp_utc\",  StringType(), nullable=False),\n",
    "    StructField(\"temp_celsius\",   DoubleType(), nullable=True),\n",
    "    StructField(\"temp_min_c\",     DoubleType(), nullable=True),\n",
    "    StructField(\"temp_max_c\",     DoubleType(), nullable=True),\n",
    "    StructField(\"pressure_hpa\",   DoubleType(), nullable=True),\n",
    "    StructField(\"humidity_pct\",   DoubleType(), nullable=True),\n",
    "    StructField(\"wind_speed_kph\", DoubleType(), nullable=True),\n",
    "    StructField(\"wind_direction\", DoubleType(), nullable=True)\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Schritt 2: JSON-Schema definiert\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Kafka-Stream lesen\n",
    "# ----------------------------------------------------------------------------\n",
    "df_raw = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"172.29.16.101:9092\") \\\n",
    "    .option(\"subscribe\", \"current-weather-api\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"‚úÖ Schritt 3: Kafka-Stream wird gelesen\")\n",
    "\n",
    "df_str = df_raw.selectExpr(\"CAST(value AS STRING) AS json_str\")\n",
    "df_json = df_str.select(from_json(col(\"json_str\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "print(\"‚úÖ Schritt 4: Kafka-Daten in DataFrame mit Schema umgewandelt\")\n",
    "\n",
    "# Timestamp umwandeln (optional f√ºr sp√§tere Verarbeitung)\n",
    "df = df_json.withColumn(\n",
    "    \"ts\", to_timestamp(col(\"timestamp_utc\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ").drop(\"timestamp_utc\")\n",
    "\n",
    "print(\"‚úÖ Schritt 5: Timestamp konvertiert\")\n",
    "\n",
    "df_raw = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"172.29.16.101:9092\") \\\n",
    "    .option(\"subscribe\", \"current-weather-api\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"‚ñ∂Ô∏è Starte Ausgabe des Kafka-Streams in der Konsole:\")\n",
    "\n",
    "df_raw.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "    .writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start() \\\n",
    "    .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d793c-42cc-423b-a697-4299d4324b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 4) In PostgreSQL schreiben (via foreachBatch)\n",
    "# ----------------------------------------------------------------------------\n",
    "def write_to_postgres(batch_df, batch_id):\n",
    "    batch_df.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/weather_db\") \\\n",
    "        .option(\"dbtable\", \"weather_api\") \\\n",
    "        .option(\"user\", \"bdeng\") \\\n",
    "        .option(\"password\", \"bdengpass\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "\n",
    "query = df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
